{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9388236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lyricsgenius import Genius\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import os\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.downloader as api\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, LdaMulticore\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import logging\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pattern.en import lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26edff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from collections import Counter\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "import time\n",
    "logging.basicConfig(format ='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.setLevel(level = logging.INFO)\n",
    " \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# add stopwords\n",
    "extended_stopwords = [\"are\", \"im\", \"youre\", \"ill\", \"youll\" \"theyre\" \"hes\", \"shes\", \"oh\", \"ooh\", \"oohooh\", \"oohoohooh\", \"ay\", \"yo\", \"wo\",\n",
    "                      \"wont\", \"might\", \"dont\", \"going\", \"even\", 'one', 'think', 'feel', 'u',\n",
    "                      \"cant\", 'yeah', 'yes', \"no\", \"cause\", \"hey\", \"really\", \"said\", \"says\", \"saying\",\n",
    "                      \"like\", 'got', 'get', 'wanna', \"wants\", 'baby', 'know', \"knows\", 'need', \"bout\",\n",
    "                      'feel', 'want', 'lets', \".\", \"ft\", \"feat\", \"lil\", \"g\", \"mc\", \"make\", \n",
    "                      \"give\", \"gimme\", \"uh\", \"uhuh\", \"come\", \"comes\", \"came\", \"coming\", \"some\", \n",
    "                      \"go\", \"aint\", \"take\", \"yeahyeah\", \"mm\", \"okay\", \"much\", \"more\", \"done\", \"did\", \n",
    "                      \"never\", \"ever\", \"always\", \"sometimes\", \"one\", \"going\", \"saying\", \"already\", \"even\",\n",
    "                      \"yet\", \"wanted\", \"all\", \"bout\", 'even', 'put', 'woah', \"woo\", 'anymore',\n",
    "                      \"see\", \"let\", \"lets\", \"day\", \"another\", \"other\", \"everybody\", \"would\", \"could\",\n",
    "                      \"nobody\", \"somebody\", \"anybody\", \"gotta\", \"whats\", \"ahah\", \"couldnt\", \"ive\", \"id\", \"youve\",\n",
    "                      \"nothing\", \"everything\", \"anything\", \"something\", \"knew\", \"tell\", \"say\", \"babe\", \"heres\", \"theres\",\n",
    "                      \"uhh\", \"its\", \"itll\", \"also\", \"ohohoh\", \"gets\", \"getting\", \"without\", \"with\", \"gonna\", \"didnt\", \"thats\", \n",
    "                      \"ya\", \"every\", \"â€¢\", \"ah\", \"ey\", \"thats\", \"ohoh\", \"tryna\", \"havent\", \"doesnt\", \"isnt\", \"whos\", \"whose\", \"still\"]\n",
    "stop_words = stop_words + extended_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf6a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def remove_chars(text):\n",
    "    '''\n",
    "    Input: text in str format\n",
    "    Output: text with removed punctuation signs\n",
    "    '''\n",
    "    stopchars = string.punctuation\n",
    "    return ''.join([c for c in text if c not in stopchars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b02854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def translate_lyrics(lyrics):\n",
    "    '''\n",
    "    Input: text in str format\n",
    "    Output: text translated to English\n",
    "    '''\n",
    "    lang = translator.detect(lyrics).lang\n",
    "    if lang != \"en\":\n",
    "        lyrics = translator.translate(lyrics, dest='en').text\n",
    "    return {'translated_lyrics': lyrics, 'lang': lang}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7226fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def scrape_lyrics(file_path, num_songs=200, a=0, create_csv=True):\n",
    "    '''\n",
    "    Create an initial dataframe of the form: \n",
    "    #Pos\tArtist and Title\tLyrics\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): accessed file, must be in excel (.xlsx) format\n",
    "    \n",
    "        num_songs (int): the number of songs need to be scraped\n",
    "    \n",
    "        a (int): the number of the song from which scraping should start \n",
    "    \n",
    "        b (int): the number of the song at which scraping should end\n",
    "    \n",
    "        create_csv (bool): set as True to create a dataframe file based on the results of scraping\n",
    "    '''\n",
    "    \n",
    "    # TODO: adjust the path\n",
    "    country = file_path.strip('.xlsx').lower()\n",
    "    \n",
    "    file = pd.read_excel(file_path)\n",
    "    file = file[a:]\n",
    "    file = file[['Artist and Title']]\n",
    "    artists = []\n",
    "    titles = []\n",
    "    \n",
    "    for el in file.iloc[:, 0]:\n",
    "        el = [word.strip() for word in el.split('-')]\n",
    "        artists.append(el[0])\n",
    "        titles.append(el[1])\n",
    "        \n",
    "    data = {'Artist': artists,\n",
    "        'Title': titles}\n",
    "    df = pd.DataFrame(data)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['Artists'], new_df['Title'], new_df['Lyrics'] = None, None, None\n",
    "    \n",
    "    #Creating a separate column for lyrics\n",
    "    df['Lyrics'] = None\n",
    "    #number of songs\n",
    "    n = len(df)\n",
    "    \n",
    "    token = \"add-your-token-for-genius.com\"\n",
    "\n",
    "    genius = Genius(token)\n",
    "    genius.verbose = False\n",
    "    genius.remove_section_headers = True\n",
    "    genius.timeout = 10\n",
    "    genius.sleep = 10\n",
    "    \n",
    "    none_indices = []\n",
    "    positive_indices = []\n",
    "    \n",
    "    j = a\n",
    "    for i in tqdm(range(a, n)):\n",
    "\n",
    "        try:\n",
    "            artist = genius.search_artist(df.iloc[i,0], max_songs=3, sort=\"title\")\n",
    "            song = artist.song(df.iloc[i,1])\n",
    "            df.iloc[i,2]=song.lyrics\n",
    "            positive_indices.append(i)\n",
    "            new_df.loc[j] = [df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]]\n",
    "            j += 1\n",
    "            print(f\"song number {i} : {df.iloc[i,1]} by {df.iloc[i,0]} was successfully scraped\")\n",
    "            if len(positive_indices) == num_songs:\n",
    "                print(f\"{num_songs} were successfully scraped\")\n",
    "                break\n",
    "            \n",
    "        except:\n",
    "            print(f'error: missing lyrics for song number {i} : {df.iloc[i,1]} by {df.iloc[i,0]}')\n",
    "            none_indices.append(i)\n",
    "            \n",
    "    if create_csv == True:    \n",
    "        new_df.to_csv(f'df_{country}.csv')\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38dfae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class Country:\n",
    "    '''\n",
    "    The class to create and work with the country object.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, country_name, num_songs=200):\n",
    "        '''\n",
    "        Initializes the instance of a Country class.\n",
    "\n",
    "        Args:\n",
    "        \n",
    "          country_name (str): name of the country. Must start with capital letter.\n",
    "          \n",
    "          num_songs (int): the number of songs to create document collection from.\n",
    "\n",
    "        '''\n",
    "        self.country_name = country_name \n",
    "        self.num_songs = num_songs\n",
    "        \n",
    "        try:\n",
    "            #if the dataframe file is already there, just read it \n",
    "            self.df = pd.read_csv(f\"data/processed_dataframes/df_{country_name.lower()}.csv\")\n",
    "            #count how many lyrics were scraped\n",
    "            self.count_indices()\n",
    "            #if the number of scraped lyrics is the same as the number of songs reqiured, confirm success\n",
    "            if len(self.present) == num_songs:\n",
    "                print(\"The file was successfully read\")\n",
    "            #if for some reason the dataframe was empty, go to scraping the lyrics from scratch\n",
    "            elif len(self.present) == 0:\n",
    "                next\n",
    "            #if the number of scraped lyrics was not 0, but less than needed, scrape more \n",
    "            elif 0 < len(self.present) < 200:\n",
    "                self.scrape_more_lyrics(n=200, a=200)\n",
    "                \n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            #if the dataframe file for the country wasn't created it, scrape the lyrics and create the df file.\n",
    "            print(\"The dataframe will be created now. Starting scraping the lyrics\")\n",
    "            \n",
    "            start = time.time()\n",
    "            self.df = scrape_lyrics(f\"data/song_charts/{country_name}.xlsx\", num_songs=200)\n",
    "            end = time.time()\n",
    "\n",
    "            print(\"Done\")\n",
    "            print(\"Overall runtime = \", str(abs(start-end)))\n",
    "\n",
    "    def count_indices(self):\n",
    "        '''\n",
    "        Create lists of the indices of missing and recalled lyrics. \n",
    "        Measure missing and recall rate.\n",
    "        '''\n",
    "        self.missing = []\n",
    "        self.present = []\n",
    "        for i in range(len(self.df['Lyrics'])):\n",
    "            #print(\"Lyrics number\", i)\n",
    "            #print(str(self.df['Lyrics'][i]))\n",
    "            if len(str(self.df['Lyrics'][i])) > 10:\n",
    "                self.present.append(i)\n",
    "            else:\n",
    "                self.missing.append(i)\n",
    "        \n",
    "        self.missing_rate = len(self.missing)/self.num_songs*100\n",
    "        self.recall_rate = len(self.present)/self.num_songs*100\n",
    "        \n",
    "        print(f\"recall_rate: {self.recall_rate}%\")\n",
    "        \n",
    "    \n",
    "    def translate_all_lyrics(self):\n",
    "        '''\n",
    "        Translate the lyrics if they are not translated yet.\n",
    "        Count the proportion of languages in the songs\n",
    "        \n",
    "        self.langs: shows languages used in the songs and their count.\n",
    "        '''\n",
    "        \n",
    "        self.langs = []\n",
    "    \n",
    "        #Check if the Translations column is already created\n",
    "        try:\n",
    "            a = self.df['Translations'][self.present[-1]]\n",
    "            if len(a) < 10:\n",
    "                next\n",
    "            \n",
    "            print(f\"Reading from df_{self.country_name.lower()}.csv file...\")\n",
    "            \n",
    "            #Count languages used in the songs \n",
    "            for i in tqdm(range(len(self.df['Languages']))):\n",
    "                lang = self.df['Languages'][i]\n",
    "                if type(lang) == str:\n",
    "                    self.langs.append(lang)\n",
    "                elif type(lang) == list:\n",
    "                    self.langs.append(tuple(lang))\n",
    "                    \n",
    "            print(\"Translations were successfully read.\")\n",
    "\n",
    "        #Create a column with translations and write it into CSV file\n",
    "        except:\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                print(f\"Filling in the missing translations for the df_{self.country_name.lower()}.csv file...\")\n",
    "                \n",
    "                for i in tqdm(range(self.last_translated, len(self.df['Lyrics']))):\n",
    "                    lyrics = self.df['Lyrics'][i]\n",
    "                    if len(str(lyrics)) > 10:\n",
    "                        result = translate_lyrics(lyrics)\n",
    "                        self.df['Translations'][i] = result['translated_lyrics']\n",
    "                        self.df['Languages'][i] = result['lang']\n",
    "                        lang = self.df['Languages'][i]\n",
    "\n",
    "                        #if there is only one language in the song, add it as it is\n",
    "                        if type(lang) == str:\n",
    "                            self.langs.append(lang)\n",
    "\n",
    "                        #if there is more than 1 language used, add as a tuple\n",
    "                        elif type(lang) == list:\n",
    "                            self.langs.append(tuple(lang))\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                #update the dataframe to add translations\n",
    "                self.df.to_csv(f'df_{self.country_name.lower()}.csv')\n",
    "                \n",
    "                \n",
    "            except:\n",
    "                \n",
    "                print(f\"Creating translations for the df_{self.country_name.lower()}.csv file...\")\n",
    "                \n",
    "                try:\n",
    "                    self.df['Translations'] = None\n",
    "                    self.df['Languages'] = None\n",
    "\n",
    "                    #Translate the lyrics using Google API\n",
    "                    #Count languages used in the songs \n",
    "\n",
    "                    for i in tqdm(range(len(self.df['Lyrics']))):\n",
    "                        self.translation_checkpoint = i \n",
    "                        lyrics = self.df['Lyrics'][i]\n",
    "                        if len(str(lyrics)) > 10:\n",
    "                            result = translate_lyrics(lyrics)\n",
    "                            self.df['Translations'][i] = result['translated_lyrics']\n",
    "                            self.df['Languages'][i] = result['lang']\n",
    "                            lang = self.df['Languages'][i]\n",
    "\n",
    "                            #if there is only one language in the song, add it as it is\n",
    "                            if type(lang) == str:\n",
    "                                self.langs.append(lang)\n",
    "\n",
    "                            #if there is more than 1 language used, add as a tuple\n",
    "                            elif type(lang) == list:\n",
    "                                self.langs.append(tuple(lang))\n",
    "                        else:\n",
    "                            continue\n",
    "                            \n",
    "                except ReadTimeout:\n",
    "                    print(\"The translation stopped at song\", self.translation_checkpoint)\n",
    "                    next\n",
    "\n",
    "                #update the dataframe to add translations\n",
    "                self.df.to_csv(f'df_{self.country_name.lower()}.csv')\n",
    "            \n",
    "            print(\"File with translations was created\")\n",
    "                         \n",
    "                        \n",
    "            #TODO: manage the error when Internet connection breaks and Google translator throws an error     \n",
    "                    \n",
    "            \n",
    "        self.langs = dict(Counter(self.langs))\n",
    "        \n",
    "                \n",
    "    def count_langs(self):\n",
    "        '''\n",
    "        To use if for some reason the self.langs variable value was lost \n",
    "        (usually after scraping new lyrics).\n",
    "        '''\n",
    "        self.langs = []\n",
    "        for i in tqdm(range(len(self.df['Languages']))):\n",
    "            lang = self.df['Languages'][i]\n",
    "            if type(lang) == str:\n",
    "                self.langs.append(lang)\n",
    "            elif type(lang) == list:\n",
    "                self.langs.append(tuple(lang))\n",
    "                \n",
    "        self.langs = dict(Counter(self.langs))\n",
    "        \n",
    "        print(f\"Here is the distribution of languages in songs for{self.country_name}:\", self.langs)\n",
    "    \n",
    "    def preprocess_lyrics(self, force_preprocess=False, delete_repetitions=False):\n",
    "        '''\n",
    "        Preprocesses the lyrics.\n",
    "\n",
    "        - removes punctuation\n",
    "        - splits sentences into words\n",
    "        - removes extra words\n",
    "        - removes words shorter than 3 letters (usually exclamations - \"ay\", \"yo\", etc.)\n",
    "        \n",
    "        If the lyrics are already preprocessed, just reads the dataframe file.\n",
    "\n",
    "        Args:\n",
    "        \n",
    "          force_preprocess: boolean, set as True if you need to preprocess from scratch\n",
    "          (usually if you added some changes into preprocessing steps and need to update\n",
    "          the dataframe).\n",
    "          \n",
    "          delete_repetitions: boolean, set as True if you want to avoid repeating words \n",
    "          in the lyrics of each song.\n",
    "          Recommended when lyrics are repetetive and inflate some words' count.\n",
    "          \n",
    "        \n",
    "        '''    \n",
    "        pattern_order = r'[0-9]'\n",
    "        \n",
    "        #if the lyrics are already processed and not to be updated, read from file.\n",
    "        #if trying to access the last processed translation throws a KeyError, process from scratch. \n",
    "        \n",
    "        if force_preprocess==False:\n",
    "            a = self.df['Processed translations'][self.present[-1]]\n",
    "            print(f\"The lyrics are already processed and translated in df_{self.country_name.lower()}.csv\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print(\"Processing translations...\")\n",
    "            \n",
    "            self.df['Processed translations'] = None\n",
    "\n",
    "            for i in self.present:\n",
    "                try:\n",
    "                    #delete headers, extra text\n",
    "                    try: \n",
    "                        self.df['Processed translations'][i] = self.df['Translations'][i].split('Lyrics'.casefold())[1]\n",
    "                    except IndexError:\n",
    "                        self.df['Processed translations'][i] = self.df['Translations'][i]\n",
    "\n",
    "                    #delete punctuation, split into words\n",
    "                    self.df['Processed translations'][i] = remove_chars(self.df['Processed translations'][i]).split()\n",
    "                    \n",
    "                    #delete the word \"Embed\" in the end, if it is present\n",
    "                    \n",
    "                    try:\n",
    "                        self.df['Processed translations'][i][-1] = re.sub(pattern_order, '', self.df['Processed translations'][i][-1].split('Embed')[0])\n",
    "                    except IndexError:\n",
    "                        next\n",
    "                        \n",
    "                    #make lowercase, lemmatize\n",
    "                    #delete if the word is a stop word and/or if it is shorter than 3 letter\n",
    "                    \n",
    "                    if delete_repetitions==True:\n",
    "                        lyrics = set()\n",
    "                        for word in self.df['Processed translations'][i]:\n",
    "                            word = lemmatizer.lemmatize(word.lower())\n",
    "                            if word not in stop_words and len(word) > 2:\n",
    "                                lyrics.add(word)\n",
    "                        \n",
    "                    else:\n",
    "                        lyrics = []\n",
    "                        for word in self.df['Processed translations'][i]:\n",
    "                            word = lemmatizer.lemmatize(word.lower())\n",
    "                            if word not in stop_words and len(word) > 2:\n",
    "                                lyrics.append(word)\n",
    "                            \n",
    "                    self.df['Processed translations'][i] = lyrics\n",
    "\n",
    "                except AttributeError:\n",
    "                    next\n",
    "                    \n",
    "            #Add preprocessed lyrics to the dataframe\n",
    "            self.df.to_csv(f'df_{self.country_name.lower()}.csv')\n",
    "            \n",
    "            print(f\"Translations are processed and are available in df_{self.country_name.lower()}.csv\")\n",
    "\n",
    "\n",
    "    def return_songs(self):\n",
    "        '''\n",
    "        Returns a list of all available processed lyrics\n",
    "        \n",
    "        self.processed_songs: list of lists of words. Each list corresponds to a song.\n",
    "        '''\n",
    "        \n",
    "        #else - just read words from the list\n",
    "        \n",
    "        self.processed_songs = []\n",
    "        index = self.present[0]\n",
    "                \n",
    "        #if the dataframe file was read in the form of a string, parse it into words.\n",
    "        #for example, type(\"['hello', 'world']\") = str\n",
    "        \n",
    "        if type(self.df['Processed translations'][index]) is type('str'):\n",
    "\n",
    "            for i in self.present:\n",
    "                current_lyrics = []\n",
    "                text = self.df['Processed translations'][i]\n",
    "                text = text.split()\n",
    "                for word in text:\n",
    "                    current_lyrics.append(word.strip(\"',[]!?-.#@\"))\n",
    "                self.processed_songs.append(current_lyrics)\n",
    "                    \n",
    "        else:\n",
    "            \n",
    "            for i in self.present:\n",
    "                self.processed_songs.append(self.df['Processed translations'][i])\n",
    "        \n",
    "        #Filter the lyrics which are too short (less than 10 words)\n",
    "        self.processed_songs = list(filter(lambda x: (len(x) > 10), self.processed_songs))\n",
    "    \n",
    "    \n",
    "    def return_songs_to_sentences(self):\n",
    "        '''\n",
    "        Divide songs into parts made of 4 lines.\n",
    "        In this case, 1 document in collection = 4 lines from a song.\n",
    "        '''   \n",
    "        \n",
    "        print(\"Dividing songs into 4-lined parts...\")\n",
    "\n",
    "        self.divided_songs = []\n",
    "\n",
    "        for i in tqdm(self.present):\n",
    "            lyrics = self.df['Translations'][i]\n",
    "            \n",
    "            #delete headers, extra text\n",
    "            try: \n",
    "                lyrics = self.df['Translations'][i].split('Lyrics'.casefold())[1]\n",
    "            except IndexError:\n",
    "                self.df['Processed translations'][i] = self.df['Translations'][i]\n",
    "\n",
    "            #delete punctuation, \n",
    "            #split into lines\n",
    "            lyrics = remove_chars(lyrics).split(\"\\n\")\n",
    "            for j in tqdm(range(0, len(lyrics), 4)):\n",
    "                self.divided_songs.append(lyrics[j:j+4])\n",
    "\n",
    "\n",
    "        for i in tqdm(range(len(self.divided_songs))):\n",
    "            united_doc = []\n",
    "            for line in self.divided_songs[i]:\n",
    "                new_line = [word.lower() for word in line.split() if word.casefold() not in stop_words]\n",
    "                united_doc.extend(new_line)\n",
    "            self.divided_songs[i] = united_doc\n",
    "            \n",
    "            \n",
    "    def find_topics(self, div_songs=False, filter_extremes=True, topics=10, epochs=50):\n",
    "        '''\n",
    "        Detect topics using gensim.models.LdaMulticore model\n",
    "        \n",
    "        div_songs: boolean, set as True to use songs divided into 4 lines sentences as input\n",
    "        \n",
    "        filter_extremes: boolean, filters the most and the least frequent words in the overall corpus\n",
    "        \n",
    "        topic: integer, number of topics you expect to see. Recommended: from 5 to 10.\n",
    "        \n",
    "        epochs: integer, number of epochs. \n",
    "        \n",
    "        Visualize with pyLDAvis.\n",
    "        '''\n",
    "        \n",
    "        if div_songs == False:\n",
    "            self.return_songs()\n",
    "            songs = self.processed_songs\n",
    "        else:\n",
    "            self.return_songs_to_sentences()\n",
    "            songs = self.divided_songs\n",
    "        \n",
    "        country_dict = corpora.Dictionary(songs)\n",
    "        \n",
    "        if filter_extremes == True:\n",
    "            #In this case, each word should be found in no less than 10 documents, \n",
    "            #and no more than 50% of the documents. \n",
    "            #Only top 15 000 unique tokens from the corpus will be saved.\n",
    "            country_dict.filter_extremes(no_below=3, no_above=0.5, keep_n=15000)\n",
    "            \n",
    "        Corpus = [country_dict.doc2bow(l) for l in songs]\n",
    "\n",
    "        print(f\"Model training started. Parameters: {topics} topics, {epochs} epochs\")\n",
    "\n",
    "        LDA_model = gensim.models.LdaMulticore(corpus=Corpus,\n",
    "                                           id2word=country_dict,\n",
    "                                           num_topics=topics,\n",
    "                                           passes=epochs)\n",
    "\n",
    "        #Compute Coherence Score\n",
    "        #Evaluation metric: u_mass (the closer to 0, the better).\n",
    "        coherence_model_lda = CoherenceModel(model=LDA_model, texts=songs, dictionary=country_dict, coherence='u_mass')\n",
    "        self.coherence_lda = coherence_model_lda.get_coherence()\n",
    "        print('\\nCoherence Score: ', self.coherence_lda)\n",
    "        doc_lda = LDA_model[Corpus]\n",
    "\n",
    "        pyLDAvis.enable_notebook()\n",
    "        lda_viz = gensimvis.prepare(LDA_model, Corpus, country_dict)\n",
    "        self.corpus = Corpus\n",
    "        self.model = LDA_model\n",
    "        self.topic_words = doc_lda\n",
    "        self.visualize = lda_viz\n",
    "\n",
    "        \n",
    "    def find_topics_2(self, topics=5, filter_extremes=True, div_songs=False, epochs=100):\n",
    "        \n",
    "        if div_songs == False:\n",
    "            self.return_songs()\n",
    "            songs = self.processed_songs\n",
    "        else:\n",
    "            self.return_songs_to_sentences()\n",
    "            songs = self.divided_songs\n",
    "            \n",
    "        country_dict = corpora.Dictionary(songs)\n",
    "        \n",
    "        if filter_extremes == True:\n",
    "            #In this case, each word should be found in no less than 10 documents, \n",
    "            #and no more than 50% of the documents. \n",
    "            #Only top 15 000 unique tokens from the corpus will be saved.\n",
    "            country_dict.filter_extremes(no_below=10, no_above=0.5, keep_n=15000)\n",
    "            \n",
    "        Corpus = [country_dict.doc2bow(l) for l in songs]\n",
    "        start = time.time()\n",
    "        LDA_model = LdaModel(corpus = Corpus, id2word=country_dict, num_topics = topics, update_every=1, chunksize=10, \n",
    "                             passes=epochs, alpha='asymmetric', eta='auto', per_word_topics=True, eval_every=None, minimum_probability=1e-8)\n",
    "        \n",
    "        self.old_model = LDA_model\n",
    "        \n",
    "        coherence_model_lda = CoherenceModel(model=LDA_model, texts=songs, dictionary=country_dict, coherence='u_mass')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        print('\\nCoherence Score: ', coherence_lda)\n",
    "        end = time.time()\n",
    "        runtime = abs(start-end)\n",
    "        print(\"Overall model training runtime is\", runtime)\n",
    "        doc_lda = LDA_model[Corpus]\n",
    "\n",
    "        pyLDAvis.enable_notebook()\n",
    "        lda_viz = gensimvis.prepare(LDA_model, Corpus, country_dict)\n",
    "        self.corpus = Corpus\n",
    "        self.topic_words = doc_lda\n",
    "        self.visualize = lda_viz\n",
    "        \n",
    "    def scrape_more_lyrics(self, n=200, a=200):\n",
    "        '''\n",
    "        Scrapes more lyrics to the dataframe file.\n",
    "        \n",
    "        n (int): the desired number of lyrics you want to have in the dataframe\n",
    "        a (int): the index of the song you want to start scraping from\n",
    "        '''\n",
    "        \n",
    "        print (\"length of self.present is\", len(self.present))\n",
    "        if n <= len(self.present):\n",
    "            print(f\"You already have {n} lyrics scraped.\")\n",
    "            return None\n",
    "        \n",
    "        #Memorize the last translated lyrics index. This will be used for further translation\n",
    "        try:\n",
    "            self.last_translated = self.present[-1]\n",
    "        except AttributeError:\n",
    "            self.last_translated = 0\n",
    "        \n",
    "        print(\"Current number of scraped songs is\", len(self.present))\n",
    "\n",
    "        missing_num = n - len(self.present)\n",
    "        \n",
    "        print(f\"Need to scrape {missing_num} more lyrics\")\n",
    "        \n",
    "        print(f\"Start scraping {missing_num} songs starting from {a}...\")\n",
    "\n",
    "        #Scrape the missing number of lyrics\n",
    "        additional_df = scrape_lyrics(f'data/song_charts/{self.country_name}.xlsx', num_songs=missing_num, a=a, create_csv=False)\n",
    "\n",
    "        print(\"Scraping has ended.\")\n",
    "    \n",
    "        #Unite old and new dataframes\n",
    "        self.df = pd.concat([self.df, additional_df])\n",
    "        self.additional_df = additional_df\n",
    "        print(\"New length of the dataframe is\", len(self.df))\n",
    "        print(\"Recounting the indices...\")\n",
    "        self.count_indices()\n",
    "        \n",
    "        #Update the dataframe file\n",
    "        self.df.to_csv(f'df_{self.country_name.lower()}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ee568eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def process_country(country, num_songs=200, topic_num=10, force_preprocess=False, delete_repetitions=False):\n",
    "    '''\n",
    "    input should be lowercase\n",
    "    type: str\n",
    "    '''\n",
    "    country = Country(country.capitalize(), num_songs=num_songs)\n",
    "    country.count_indices()\n",
    "    country.translate_all_lyrics()\n",
    "    print(f\"This is the proportion of languages in the songs of {country.country_name}:\", country.langs)\n",
    "    country.preprocess_lyrics(force_preprocess=force_preprocess, delete_repetitions=delete_repetitions)\n",
    "    return country\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15353cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start processing the chosen country\n",
    "\n",
    "germany = process_country('germany', force_preprocess=True, delete_repetitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84babde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "germany.count_langs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd658720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to iterate through different number of clusters \n",
    "\n",
    "# iterate and save the results for each cluster number in the dictionary \n",
    "\n",
    "topics_results = defaultdict(dict)\n",
    "\n",
    "for i in range(3, 8):\n",
    "    germany.find_topics(filter_extremes=False, topics=i, epochs=200)\n",
    "    topics_results[i] = {'visual': germany.visualize}\n",
    "    name = germany.country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ac1aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1068821880459721926528044436\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1068821880459721926528044436_data = {\"mdsDat\": {\"x\": [-0.06746308328987546, -0.09539882957809638, 0.16286191286797186], \"y\": [0.10409191606992932, -0.092832421767997, -0.011259494301932472], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [39.84471940767794, 37.17676710396097, 22.978513488361095]}, \"tinfo\": {\"Term\": [\"bonez\", \"gzuz\", \"love\", \"taste\", \"thunder\", \"wit\", \"maxwell\", \"sugar\", \"tamam\", \"magical\", \"christmas\", \"today\", \"bye\", \"solo\", \"sa4\", \"camora\", \"million\", \"raf\", \"beggin\", \"brrm\", \"layin\", \"high\", \"pop\", \"low\", \"made\", \"ride\", \"watermelon\", \"hope\", \"paradise\", \"well\", \"thunder\", \"solo\", \"layla\", \"swallalala\", \"pink\", \"shimmy\", \"wie\", \"raver\", \"woop\", \"nana\", \"thun\", \"cardboard\", \"dddddown\", \"havana\", \"psycho\", \"believer\", \"thththunder\", \"woulda\", \"nah\", \"innocence\", \"drank\", \"ceiling\", \"sad\", \"pharrell\", \"teenager\", \"mojaja\", \"ching\", \"wearing\", \"goosebump\", \"immamama\", \"standard\", \"cherry\", \"coco\", \"made\", \"nigga\", \"well\", \"berlin\", \"benz\", \"lead\", \"dance\", \"friend\", \"back\", \"first\", \"body\", \"ask\", \"time\", \"mind\", \"girl\", \"night\", \"fuck\", \"bitch\", \"ice\", \"hand\", \"look\", \"new\", \"right\", \"way\", \"lyric\", \"love\", \"around\", \"heart\", \"better\", \"last\", \"call\", \"today\", \"life\", \"christmas\", \"beggin\", \"layin\", \"babadum\", \"wishin\", \"livin\", \"tree\", \"save\", \"doodoodoo\", \"suv\", \"santa\", \"favorite\", \"oohwoah\", \"underneath\", \"bababadum\", \"madonna\", \"breakin\", \"riririririse\", \"blade\", \"paradise\", \"kak\", \"luna\", \"loving\", \"thrill\", \"tanzouyem\", \"sucker\", \"inna\", \"mek\", \"dadam\", \"knee\", \"fuckin\", \"awake\", \"monster\", \"facetime\", \"low\", \"hope\", \"rockstar\", \"middle\", \"ride\", \"love\", \"tear\", \"para\", \"show\", \"fire\", \"light\", \"home\", \"fool\", \"alone\", \"high\", \"black\", \"thing\", \"life\", \"heart\", \"head\", \"kiss\", \"lyric\", \"eye\", \"night\", \"lalalala\", \"away\", \"tonight\", \"stay\", \"look\", \"way\", \"time\", \"right\", \"mind\", \"around\", \"bonez\", \"gzuz\", \"tamam\", \"magical\", \"bye\", \"sa4\", \"brrm\", \"maxwell\", \"watermelon\", \"wit\", \"sugar\", \"primo\", \"eightfour\", \"145k\", \"110k\", \"justin\", \"moya\", \"230k\", \"vamo\", \"enchant\", \"115k\", \"durk\", \"culprit\", \"kahba\", \"170k\", \"175k\", \"cole\", \"dave\", \"kanye\", \"minaj\", \"camora\", \"raf\", \"taste\", \"mhm\", \"million\", \"pop\", \"today\", \"polo\", \"lick\", \"far\", \"fly\", \"stay\", \"drop\", \"high\", \"beautiful\", \"drake\", \"talk\", \"easy\", \"good\", \"back\", \"way\", \"night\", \"time\", \"love\", \"lyric\"], \"Freq\": [106.0, 75.0, 398.0, 87.0, 87.0, 51.0, 49.0, 44.0, 40.0, 38.0, 57.0, 103.0, 33.0, 52.0, 29.0, 32.0, 47.0, 33.0, 40.0, 25.0, 38.0, 117.0, 39.0, 52.0, 68.0, 63.0, 20.0, 44.0, 35.0, 110.0, 86.75883546086298, 51.83069159967923, 28.24410147265273, 25.623396331674112, 25.616369602254903, 24.749817916030253, 23.00267162182607, 22.129075142610443, 22.1290706267175, 22.976651046688875, 21.255498232264234, 21.25549221107364, 21.255463610418335, 18.63475545884442, 17.76117252730762, 16.887592606366116, 14.266863380625134, 14.266843811755715, 13.359325450050399, 12.51968321722388, 12.518981748520078, 11.646122865151796, 11.645677297048092, 10.77255874983559, 10.77255874983559, 10.772535417722052, 10.772530149180284, 10.771690945741723, 10.728211928487138, 9.898957754727018, 19.508827612116708, 16.895335857465604, 16.891199299529873, 56.18245892949694, 39.216228068720184, 85.69038121175497, 22.999594793434284, 44.83900249911306, 19.380460344618463, 99.85017427600074, 51.540939866079285, 109.2098862438165, 29.769148625435093, 51.368812090666346, 34.93180474506283, 85.35747560519233, 61.87144839281443, 52.747399803523415, 99.31549857274774, 44.74041754557347, 45.31915933216364, 33.52157266505696, 46.77532406458976, 54.61345106421275, 40.75534373331744, 47.090418989385455, 54.83202028265084, 63.11558291978382, 100.45962714519817, 42.81401288099946, 50.15768271991922, 38.460987122348314, 35.086148934066486, 36.621681990262346, 37.73427758758991, 38.31207103666206, 57.40407228107106, 40.09587354646831, 38.34483245545384, 23.65306887769134, 23.6530632596721, 22.775260393848313, 21.92223861089547, 20.183357722527607, 17.595168561925036, 18.432496408128845, 16.72977168708963, 16.729768878080012, 16.72976045105115, 16.72136572580066, 15.864373407749419, 15.864360767206128, 15.86408969777776, 14.998941420293761, 14.994521443656103, 34.026306009243775, 13.268136434584475, 13.268136434584475, 12.392297066485328, 12.38991081281282, 11.537314594817465, 11.536564589248826, 10.671902972681556, 10.671902972681556, 10.671902972681556, 10.6718952479051, 23.753035912061232, 27.79131027745614, 23.654824508704074, 11.481075413207945, 48.20979053223797, 41.19611205259589, 17.845087552354578, 29.667411285779306, 54.448123367454606, 278.7800474136976, 38.0358919593858, 31.458458291807148, 35.8381958666548, 36.22644874935412, 53.29917101649048, 36.459138679277096, 26.58201197281751, 59.256057941803306, 75.99713729711976, 54.45219643140415, 62.49849212858253, 72.04096185589954, 75.3226659971716, 58.436540621097485, 34.059283782186974, 79.81851960269668, 57.584652273526466, 93.92690525349015, 34.91871712959832, 47.168187292926085, 45.927742689616736, 49.56192978508227, 51.78369909025988, 47.80877631883328, 49.998871231531545, 40.02115669957596, 40.35552996874688, 37.145669057525524, 105.97225158132841, 74.75652033400314, 39.51371449107908, 37.91177476878025, 33.08691626679167, 29.101097615061022, 25.096218793656764, 48.40718827181555, 20.290375319748474, 49.94844727539578, 43.57953446347112, 16.285515596710624, 15.484564833927614, 12.28067323582405, 11.479699902244379, 10.678726568664706, 10.678713547051247, 9.877753235085034, 9.877742817794266, 9.87773500482619, 9.076779033397797, 9.076779033397797, 9.07676861610703, 9.07676861610703, 8.275805699818125, 8.275805699818125, 8.275805699818125, 8.275805699818125, 8.275805699818125, 8.275805699818125, 29.916768009698004, 29.11799966933071, 72.07329708194723, 12.290188562832272, 35.33220355985741, 29.72586421152961, 55.93454895863975, 13.892610084829085, 13.08689862016549, 25.931605647285693, 29.52490425534067, 36.13986653032472, 13.851040754130368, 31.509457177795618, 22.46154011657575, 17.07473822630496, 19.077830453895164, 15.500145628485003, 19.228275230939104, 22.848973049926794, 19.21072904085698, 19.842345006004965, 18.831310476536125, 19.112433221393353, 18.033089043934105], \"Total\": [106.0, 75.0, 398.0, 87.0, 87.0, 51.0, 49.0, 44.0, 40.0, 38.0, 57.0, 103.0, 33.0, 52.0, 29.0, 32.0, 47.0, 33.0, 40.0, 25.0, 38.0, 117.0, 39.0, 52.0, 68.0, 63.0, 20.0, 44.0, 35.0, 110.0, 87.32876899206809, 52.38624057949137, 28.79960813357057, 26.17888099695995, 26.178556217090563, 25.30530258131609, 23.558145971258668, 22.684562832163813, 22.684562471661614, 23.557164110805775, 21.810983287713082, 21.81097990062701, 21.81097987699805, 19.190246147634944, 18.316663275866844, 17.44308594690807, 14.82234853422148, 14.822347028256148, 13.94756925326979, 13.075184680520287, 13.075155843152663, 12.201608994279626, 12.201584620172463, 11.328033197415683, 11.328033197415683, 11.32802955269896, 11.328026920359699, 11.327936789431329, 11.326556290304291, 10.454448726709597, 20.86382306456339, 18.2436812229546, 18.243339407741384, 68.0028463367144, 46.531804186175684, 110.54580718364603, 26.15276270675286, 55.31992447282786, 21.726700929413425, 141.4592676703381, 66.46543732242098, 158.4145184623414, 35.53088766487611, 70.83670674322215, 45.98074780666806, 154.18765731326, 105.0611694254684, 85.00047420630821, 213.08474883224284, 68.82690531782877, 76.577270605184, 48.4602964254068, 83.84505453961756, 116.5225232592002, 70.43415785898782, 91.79320425586985, 121.85152564234109, 160.96719156641458, 398.35210778028915, 85.61686851714099, 133.12335956168914, 77.62509947149209, 60.75246948723499, 82.5367098789411, 103.15981274522444, 122.28280229321716, 57.962301527475496, 40.65408643710648, 38.92280395607603, 24.211282001389627, 24.211280860362642, 23.345554137573842, 22.480460225524368, 20.749414204892993, 18.153402139914792, 19.01824552360183, 17.287994753818584, 17.287993332911547, 17.28799131273212, 17.28777059490833, 16.422586609224705, 16.42258491038792, 16.42257552046675, 15.557172090475321, 15.557051797088693, 35.39592056002384, 13.826350402870052, 13.826350402870052, 12.96066690669994, 12.96061538343408, 12.095528613751679, 12.095505226760405, 11.230115872001344, 11.230115872001344, 11.230116201285204, 11.230113711087922, 25.02773665416843, 29.41065422516084, 25.08260001326761, 12.094738618209089, 52.66074534724777, 44.93633807190347, 19.02249953118132, 32.88833886876838, 63.803360596804296, 398.35210778028915, 44.093656734770356, 36.147762585206536, 43.22050332975744, 43.85628564296765, 70.54003774737636, 45.67304547148846, 31.17066181483869, 85.5375698309738, 117.84987394689315, 80.32897574465704, 98.70747881141196, 122.28280229321716, 133.12335956168914, 94.69562303364918, 44.93164119201052, 160.96719156641458, 98.41299187178211, 213.08474883224284, 46.81642575282751, 81.2023697006823, 81.58603972705639, 105.44954778075325, 116.5225232592002, 121.85152564234109, 154.18765731326, 91.79320425586985, 105.0611694254684, 85.61686851714099, 106.57525687000313, 75.33618636558799, 40.09339910216529, 38.49145735900677, 33.68668524196049, 29.680763508673998, 25.67590202690822, 49.76841140933617, 20.870063359142872, 51.37585682200378, 44.96453372297951, 16.8651964857059, 16.06423072754059, 12.860337815657452, 12.05936448207778, 11.258391148498108, 11.258390495016938, 10.457417814918436, 10.457416992354489, 10.457417822381032, 9.656443613231199, 9.656443613231199, 9.656443660814409, 9.656443660814409, 8.855470301596915, 8.855470301596915, 8.855470301596915, 8.855470301596915, 8.855470301596915, 8.855470301596915, 32.209816477815274, 33.139323926436425, 87.71989562521247, 13.723325567959247, 47.376833175013616, 39.1774885927201, 103.15981274522444, 17.0804875533961, 16.27994191262738, 44.66830179161687, 57.54444014076733, 105.44954778075325, 19.689503136230865, 117.84987394689315, 60.80012444967376, 33.249302982326455, 46.248412574806196, 28.199341827498344, 73.92845935044312, 158.4145184623414, 121.85152564234109, 213.08474883224284, 154.18765731326, 398.35210778028915, 160.96719156641458], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.0042, -5.5194, -6.1265, -6.2238, -6.2241, -6.2585, -6.3317, -6.3704, -6.3704, -6.3329, -6.4107, -6.4107, -6.4107, -6.5423, -6.5903, -6.6408, -6.8094, -6.8094, -6.8751, -6.94, -6.9401, -7.0124, -7.0124, -7.0903, -7.0903, -7.0903, -7.0903, -7.0904, -7.0945, -7.1749, -6.4965, -6.6403, -6.6405, -5.4387, -5.7982, -5.0166, -6.3319, -5.6643, -6.5031, -4.8637, -5.525, -4.7741, -6.0739, -5.5283, -5.9139, -5.0205, -5.3423, -5.5018, -4.869, -5.6665, -5.6536, -5.9551, -5.622, -5.4671, -5.7598, -5.6153, -5.4631, -5.3224, -4.8576, -5.7105, -5.5522, -5.8177, -5.9095, -5.8667, -5.8368, -5.8216, -5.3479, -5.7068, -5.7514, -6.2345, -6.2345, -6.2724, -6.3105, -6.3932, -6.5304, -6.4839, -6.5808, -6.5808, -6.5808, -6.5813, -6.634, -6.634, -6.634, -6.6901, -6.6903, -5.8709, -6.8127, -6.8127, -6.881, -6.8811, -6.9524, -6.9525, -7.0304, -7.0304, -7.0304, -7.0304, -6.2303, -6.0733, -6.2345, -6.9573, -5.5225, -5.6797, -6.5163, -6.008, -5.4008, -3.7676, -5.7595, -5.9494, -5.819, -5.8082, -5.4221, -5.8018, -6.1178, -5.3162, -5.0673, -5.4007, -5.2629, -5.1208, -5.0763, -5.3301, -5.8699, -5.0183, -5.3448, -4.8555, -5.845, -5.5443, -5.571, -5.4948, -5.451, -5.5308, -5.486, -5.7086, -5.7003, -5.7832, -4.2537, -4.6027, -5.2403, -5.2816, -5.4178, -5.5461, -5.6942, -5.0373, -5.9068, -5.0059, -5.1423, -6.1266, -6.1771, -6.4089, -6.4763, -6.5487, -6.5487, -6.6266, -6.6266, -6.6266, -6.7112, -6.7112, -6.7112, -6.7112, -6.8036, -6.8036, -6.8036, -6.8036, -6.8036, -6.8036, -5.5185, -5.5456, -4.6392, -6.4081, -5.3521, -5.5249, -4.8927, -6.2855, -6.3453, -5.6614, -5.5317, -5.3295, -6.2885, -5.4666, -5.8051, -6.0793, -5.9684, -6.1761, -5.9605, -5.788, -5.9614, -5.9291, -5.9814, -5.9666, -6.0247], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9136, 0.9095, 0.9007, 0.8987, 0.8985, 0.898, 0.8963, 0.8954, 0.8954, 0.8952, 0.8944, 0.8944, 0.8944, 0.8908, 0.8894, 0.8878, 0.882, 0.882, 0.8771, 0.8768, 0.8767, 0.8736, 0.8735, 0.8699, 0.8699, 0.8699, 0.8699, 0.8698, 0.8659, 0.8656, 0.853, 0.8434, 0.8432, 0.7292, 0.7491, 0.6655, 0.7917, 0.7101, 0.8059, 0.5718, 0.6659, 0.5482, 0.7433, 0.5988, 0.6454, 0.3289, 0.3907, 0.443, 0.1568, 0.4895, 0.3956, 0.5516, 0.3366, 0.1624, 0.3731, 0.2527, 0.1217, -0.0161, -0.4574, 0.2272, -0.0559, 0.2179, 0.3712, 0.1076, -0.0855, -0.2404, 0.9798, 0.9757, 0.9745, 0.9662, 0.9662, 0.9648, 0.9643, 0.9618, 0.9583, 0.9582, 0.9567, 0.9567, 0.9567, 0.9562, 0.9549, 0.9549, 0.9549, 0.9529, 0.9527, 0.95, 0.9483, 0.9483, 0.9446, 0.9445, 0.9422, 0.9422, 0.9385, 0.9385, 0.9385, 0.9385, 0.9372, 0.9329, 0.9309, 0.9374, 0.9012, 0.9026, 0.9256, 0.8864, 0.8309, 0.6326, 0.8417, 0.8505, 0.8022, 0.7984, 0.7092, 0.7642, 0.8302, 0.6224, 0.5508, 0.6007, 0.5325, 0.4604, 0.42, 0.5068, 0.7124, 0.288, 0.4536, 0.1703, 0.6963, 0.4463, 0.4149, 0.2345, 0.1785, 0.0539, -0.1367, 0.1594, 0.0327, 0.1545, 1.4649, 1.4629, 1.456, 1.4554, 1.4526, 1.4509, 1.4478, 1.4429, 1.4424, 1.4424, 1.4393, 1.4356, 1.4339, 1.4245, 1.4213, 1.4178, 1.4177, 1.4136, 1.4136, 1.4136, 1.4087, 1.4087, 1.4087, 1.4087, 1.4029, 1.4029, 1.4029, 1.4029, 1.4029, 1.4029, 1.3968, 1.3412, 1.2741, 1.3603, 1.1773, 1.1945, 0.8585, 1.264, 1.2523, 0.9268, 0.8033, 0.3998, 1.1189, 0.1515, 0.4748, 0.8042, 0.5851, 0.8722, 0.1239, -0.4657, -0.3767, -0.9033, -0.632, -1.5664, -0.7184]}, \"token.table\": {\"Topic\": [3, 3, 3, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 2, 3, 3, 1, 2, 3, 2, 3, 1, 1, 1, 3, 1, 2, 1, 3, 3, 3, 2, 1, 2, 3, 3, 1, 2, 1, 2, 3, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 3, 2, 3, 1, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 2, 3, 1, 3, 2, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 1, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 2, 3, 1, 1, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 3, 1, 1, 3, 1, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 3, 1, 1], \"Freq\": [0.9121542031794319, 0.9320201474244882, 0.9331014606311514, 0.9033964010423424, 0.9033964010423424, 0.956259009344937, 0.25719692578913594, 0.6897553918890463, 0.046763077416206535, 0.5022374766181872, 0.432157828717975, 0.07007964790021216, 0.7611881422016444, 0.17398586107466157, 0.0652446979029981, 0.03400128376418431, 0.9520359453971607, 0.2339833193296618, 0.5788008425523213, 0.18472367315499616, 0.9742679628197342, 0.9912734071092353, 0.6880682468880635, 0.16412637081733622, 0.14518871264610514, 0.5263147121760818, 0.09868400853301534, 0.36184136462105626, 0.983910930131996, 0.9745981904660276, 0.8134501344466438, 0.07230667861747944, 0.10846001792621918, 0.8794481966550023, 0.11471063434630466, 0.48953238396757925, 0.39935536586828835, 0.10305944925633248, 0.5876417329106748, 0.27423280869164823, 0.1436457569337205, 0.27387377712784167, 0.6722356347683386, 0.049795232205062115, 0.9641929714990768, 0.7199657119136162, 0.1694036969208509, 0.09881882320382969, 0.9946023412291203, 0.9742686206594019, 0.9736756268114797, 0.979615529488038, 0.4482853757348571, 0.4240537338032432, 0.13327403062387644, 0.062092871636741966, 0.9313930745511295, 0.9628178144988481, 0.983476851751753, 0.931829480697691, 0.05481349886457006, 0.9710428901108858, 0.9833978033632887, 0.9318469398637738, 0.05481452587433963, 0.9033964010423424, 0.9320201428318544, 0.9795090097768651, 0.7069172748231928, 0.2474210461881175, 0.0494842092376235, 0.9033964010423424, 0.9628178155419183, 0.9915496754419658, 0.0300758184474287, 0.45113727671143045, 0.5112889136062878, 0.9942520116735725, 0.2031539329522012, 0.1015769664761006, 0.7110387653327042, 0.9320201474244882, 0.10638546170161234, 0.3546182056720411, 0.5673891290752658, 0.933751528747899, 0.9562590086625339, 0.3454828407645312, 0.5893530813042003, 0.07112882015740347, 0.9094863764512514, 0.06716172049690561, 0.35819584265016324, 0.5820682443065153, 0.9833414250361094, 0.0912069944218224, 0.8208629497964016, 0.0912069944218224, 0.8443357870188072, 0.08443357870188072, 0.08443357870188072, 0.39969108994260005, 0.10426724085459133, 0.5213362042729566, 0.12832579634532537, 0.8661991253309462, 0.7823615114085571, 0.10531789576653654, 0.12036330944747033, 0.6538140832018972, 0.20340882588503467, 0.14529201848931048, 0.958936092848921, 0.03995567053537171, 0.6235259331772841, 0.21176352447530405, 0.16470496348079205, 0.270531811101243, 0.47343066942717527, 0.25700522054618086, 0.9711689694612803, 0.9955375181329652, 0.5605578081864335, 0.3578028562892129, 0.08348733313414967, 0.9900863101926188, 0.28512405468208185, 0.6124887100578055, 0.09504135156069395, 0.37559148270165227, 0.5633872240524783, 0.06009463723226436, 0.08485371825265009, 0.6448882587201407, 0.2715318984084803, 0.13136851151617465, 0.788211069097048, 0.06568425575808733, 0.06676111425011189, 0.9124018947515291, 0.022253704750037295, 0.7016052832515166, 0.22698994458137303, 0.08254179802959019, 0.9565305891693221, 0.9795090384975401, 0.994249818847125, 0.9770490165877229, 0.9320201428318544, 0.9402336568369829, 0.9033964010423424, 0.20030427915017554, 0.7567050545673297, 0.04451206203337234, 0.9795092269759724, 0.2563202937224496, 0.7476008566904779, 0.5761082684441993, 0.3950456697903081, 0.03292047248252567, 0.976291431698564, 0.9722354509178721, 0.8745000017134659, 0.046026315879656096, 0.046026315879656096, 0.18427584177515272, 0.7985286476923285, 0.31075506356880245, 0.588799067814573, 0.09813317796909551, 0.15593980881317476, 0.7513463515543874, 0.08505807753445896, 0.9851982893386246, 0.4720117489873993, 0.4462656535880866, 0.08582031799770896, 0.2510341932347825, 0.700385399125043, 0.04769649671460867, 0.9258782812940491, 0.056968430283655114, 0.9114948845384818, 0.03797895352243674, 0.9402336568369829, 0.391384103722816, 0.49699568726706794, 0.11182402963509029, 0.8234949420016539, 0.17646320185749725, 0.9742680636030314, 0.987232040750679, 0.020093066499052605, 0.964467191954525, 0.9795090384975401, 0.0728686348689975, 0.8744236184279699, 0.09121774170384987, 0.9121774170384986, 0.06332208801119679, 0.18996626403359038, 0.7387576934639626, 0.9033964010423424, 0.590132399430253, 0.38073058027758255, 0.028554793520818692, 0.9710426644657892, 0.0398682751975889, 0.9568386047421336, 0.9770490732994824, 0.9320620506653768, 0.9763484217291587, 0.5821039286376327, 0.25555782232871677, 0.15617422475643805, 0.8381364247979592, 0.1504347429124542, 0.46460387494902616, 0.4411390327798834, 0.09385936867657094, 0.9833415399439712, 0.055328458996200765, 0.8575911144411119, 0.08299268849430115, 0.9605626711231692, 0.028251843268328504, 0.9710423520394944, 0.9931792947017455, 0.17563901443805754, 0.8196487340442686, 0.10209944903776383, 0.15314917355664576, 0.7657458677832287, 0.9486992940497788, 0.9827117378805524, 0.12070252274546424, 0.8750932899046158, 0.9698225248055832, 0.09403893374701834, 0.8463504037231651, 0.06269262249801223, 0.5120204745112655, 0.43576210596703446, 0.05447026324587931, 0.9641855160285562, 0.052569327093993035, 0.9462478876918746, 0.977063814127455, 0.9834788163629837, 0.9833413442148939, 0.9638826331436253, 0.987935232928552, 0.13882300153290864, 0.8329380091974518, 0.02313716692215144, 0.9926270605560007, 0.9585970863589919, 0.0479298543179496, 0.18966416092730196, 0.47416040231825485, 0.3413954896691435, 0.9921040729618217, 0.02223975024762553, 0.9785490108955233, 0.9464595447388573, 0.9931669731421781, 0.4324472751935056, 0.15135654631772696, 0.4108249114338303, 0.9976704618651241, 0.9921021547050809, 0.06839953419045655, 0.10259930128568481, 0.8207944102854785, 0.11339499534084266, 0.8618019645904043, 0.02267899906816853, 0.9710423520394944, 0.33432117198585304, 0.6281185655491784, 0.03039283381689573, 0.9258819620045269, 0.9445196871249613, 0.9628176649802882, 0.9962352727988419, 0.5512762920271056, 0.3242801717806504, 0.12322646527664713, 0.3683604980347265, 0.08724327585032995, 0.5428470497353864, 0.4289949618475346, 0.5638219498567598, 0.01225699890992956, 0.9786276517160066, 0.983354094541659, 0.9562590845627643, 0.9583104591409057, 0.4513689895146339, 0.3939220272127714, 0.15592746910505537, 0.9710506162307257, 0.7779580446423544, 0.10855228529893317, 0.11759830907384426, 0.976307729311992, 0.9912734538258758, 0.01946439557133984, 0.9732197785669918, 0.9698225402179657, 0.9445197830891092], \"Term\": [\"110k\", \"115k\", \"145k\", \"170k\", \"175k\", \"230k\", \"alone\", \"alone\", \"alone\", \"around\", \"around\", \"around\", \"ask\", \"ask\", \"ask\", \"awake\", \"awake\", \"away\", \"away\", \"away\", \"bababadum\", \"babadum\", \"back\", \"back\", \"back\", \"beautiful\", \"beautiful\", \"beautiful\", \"beggin\", \"believer\", \"benz\", \"benz\", \"benz\", \"berlin\", \"berlin\", \"better\", \"better\", \"better\", \"bitch\", \"bitch\", \"bitch\", \"black\", \"black\", \"black\", \"blade\", \"body\", \"body\", \"body\", \"bonez\", \"breakin\", \"brrm\", \"bye\", \"call\", \"call\", \"call\", \"camora\", \"camora\", \"cardboard\", \"ceiling\", \"cherry\", \"cherry\", \"ching\", \"christmas\", \"coco\", \"coco\", \"cole\", \"culprit\", \"dadam\", \"dance\", \"dance\", \"dance\", \"dave\", \"dddddown\", \"doodoodoo\", \"drake\", \"drake\", \"drake\", \"drank\", \"drop\", \"drop\", \"drop\", \"durk\", \"easy\", \"easy\", \"easy\", \"eightfour\", \"enchant\", \"eye\", \"eye\", \"eye\", \"facetime\", \"far\", \"far\", \"far\", \"favorite\", \"fire\", \"fire\", \"fire\", \"first\", \"first\", \"first\", \"fly\", \"fly\", \"fly\", \"fool\", \"fool\", \"friend\", \"friend\", \"friend\", \"fuck\", \"fuck\", \"fuck\", \"fuckin\", \"fuckin\", \"girl\", \"girl\", \"girl\", \"good\", \"good\", \"good\", \"goosebump\", \"gzuz\", \"hand\", \"hand\", \"hand\", \"havana\", \"head\", \"head\", \"head\", \"heart\", \"heart\", \"heart\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"hope\", \"hope\", \"hope\", \"ice\", \"ice\", \"ice\", \"immamama\", \"inna\", \"innocence\", \"justin\", \"kahba\", \"kak\", \"kanye\", \"kiss\", \"kiss\", \"kiss\", \"knee\", \"lalalala\", \"lalalala\", \"last\", \"last\", \"last\", \"layin\", \"layla\", \"lead\", \"lead\", \"lead\", \"lick\", \"lick\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"livin\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"loving\", \"low\", \"low\", \"low\", \"luna\", \"lyric\", \"lyric\", \"lyric\", \"made\", \"made\", \"madonna\", \"magical\", \"maxwell\", \"maxwell\", \"mek\", \"mhm\", \"mhm\", \"middle\", \"middle\", \"million\", \"million\", \"million\", \"minaj\", \"mind\", \"mind\", \"mind\", \"mojaja\", \"monster\", \"monster\", \"moya\", \"nah\", \"nana\", \"new\", \"new\", \"new\", \"nigga\", \"nigga\", \"night\", \"night\", \"night\", \"oohwoah\", \"para\", \"para\", \"para\", \"paradise\", \"paradise\", \"pharrell\", \"pink\", \"polo\", \"polo\", \"pop\", \"pop\", \"pop\", \"primo\", \"psycho\", \"raf\", \"raf\", \"raver\", \"ride\", \"ride\", \"ride\", \"right\", \"right\", \"right\", \"riririririse\", \"rockstar\", \"rockstar\", \"sa4\", \"sad\", \"santa\", \"save\", \"shimmy\", \"show\", \"show\", \"show\", \"solo\", \"standard\", \"standard\", \"stay\", \"stay\", \"stay\", \"sucker\", \"sugar\", \"sugar\", \"suv\", \"swallalala\", \"talk\", \"talk\", \"talk\", \"tamam\", \"tanzouyem\", \"taste\", \"taste\", \"taste\", \"tear\", \"tear\", \"tear\", \"teenager\", \"thing\", \"thing\", \"thing\", \"thrill\", \"thththunder\", \"thun\", \"thunder\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"tonight\", \"tonight\", \"tonight\", \"tree\", \"underneath\", \"vamo\", \"watermelon\", \"way\", \"way\", \"way\", \"wearing\", \"well\", \"well\", \"well\", \"wie\", \"wishin\", \"wit\", \"wit\", \"woop\", \"woulda\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1068821880459721926528044436\", ldavis_el1068821880459721926528044436_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1068821880459721926528044436\", ldavis_el1068821880459721926528044436_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1068821880459721926528044436\", ldavis_el1068821880459721926528044436_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.067463  0.104092       1        1  39.844719\n",
       "0     -0.095399 -0.092832       2        1  37.176767\n",
       "2      0.162862 -0.011259       3        1  22.978513, topic_info=         Term        Freq       Total Category  logprob  loglift\n",
       "3280    bonez  106.000000  106.000000  Default  30.0000  30.0000\n",
       "3461     gzuz   75.000000   75.000000  Default  29.0000  29.0000\n",
       "110      love  398.000000  398.000000  Default  28.0000  28.0000\n",
       "1069    taste   87.000000   87.000000  Default  27.0000  27.0000\n",
       "3639  thunder   87.000000   87.000000  Default  26.0000  26.0000\n",
       "...       ...         ...         ...      ...      ...      ...\n",
       "89        way   19.210729  121.851526   Topic3  -5.9614  -0.3767\n",
       "112     night   19.842345  213.084749   Topic3  -5.9291  -0.9033\n",
       "125      time   18.831310  154.187657   Topic3  -5.9814  -0.6320\n",
       "110      love   19.112433  398.352108   Topic3  -5.9666  -1.5664\n",
       "48      lyric   18.033089  160.967192   Topic3  -6.0247  -0.7184\n",
       "\n",
       "[219 rows x 6 columns], token_table=      Topic      Freq    Term\n",
       "term                         \n",
       "1856      3  0.912154    110k\n",
       "1857      3  0.932020    115k\n",
       "1863      3  0.933101    145k\n",
       "1870      3  0.903396    170k\n",
       "1871      3  0.903396    175k\n",
       "...     ...       ...     ...\n",
       "1150      2  0.991273  wishin\n",
       "2450      1  0.019464     wit\n",
       "2450      3  0.973220     wit\n",
       "4623      1  0.969823    woop\n",
       "4428      1  0.944520  woulda\n",
       "\n",
       "[311 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_results[3]['visual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to examine a specific number of clusters \n",
    "\n",
    "germany.find_topics(topics=5, filter_extremes=True, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "germany.visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
